# Vzlet_robot

Мы хотим создать робота, которого можно использовать в горнодобывающей промышленности без человека
Наш будущий робот должен быть полностью самостоятельным. Его возможности брать руду или породу, анализировать ее химический состав,также анализировать состав почв, и отвозить в определенный склад. Также должен протянуть «руку помощи» коллегам: он оснащен манипулятором, который способен нажимать на кнопки и выполнять физически тяжелую работу. Тут находится именно код для cv.

код Vzlet_robot.ipynb открывается в Colab
руды.zip является датасетом.

обьяснение будет идти по блокам в Colab:


1. сначала мы устанавливаем библиотеку torchmetrics


2. далее распаковываем zip файл с датасетом

   
3. импортируем все нужные библиотеки

   
4.  1. Сначала определяется словарь data_transforms, который содержит два ключа: 'train' и 'val'. Каждый из ключей содержит последовательность
        преобразований с помощью transforms.Compose:
      - Для 'train':
          - Выполнение случайного изменения размера подготовленного изображения до размера 224x224 (transforms.RandomResizedCrop(224)).
          - Случайное отражение изображения по горизонтали (transforms.RandomHorizontalFlip()).
          - Преобразование изображения в тензор (transforms.ToTensor()).
          - Нормализация значений тензора с помощью средних и стандартных отклонений [0.485, 0.456, 0.406] и [0.229, 0.224, 0.225] соответственно
           (transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])).
            Для 'val':
          - Изменение размера изображения до 256x256 (transforms.Resize(256)).
          - Вырезание центральной области изображения размером 224x224 (transforms.CenterCrop(224)).
          - Преобразование изображения в тензор (transforms.ToTensor()).
          - Нормализация значений тензора с помощью средних и стандартных отклонений [0.485, 0.456, 0.406] и [0.229, 0.224, 0.225] соответственно
            (transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])).
  
    2. Затем задается переменная data_dir, содержащая путь к каталогу с изображениями.
    
    3. Создаются наборы данных image_datasets для обучения и валидации. Каждый набор данных создается с использованием datasets.ImageFolder, который принимает
    путь к каталогу изображений и соответствующие преобразования из data_transforms.
    
    4. Создаются загрузчики данных dataloaders для обучения и валидации. Загрузчики данных создаются с использованием torch.utils.data.DataLoader, который
       принимает набор данных, размер пакета, флаг перемешивания и количество рабочих процессов.
    
    5. Вычисляются размеры наборов данных dataset_sizes для обучения и валидации.
    
    6. Определяется список классов class_names, извлекаемый из набора данных для обучения.
    
    7. Наконец, выбирается устройство для обработки тензоров на основе доступности CUDA (GPU). Если CUDA доступен, выбирается "cuda:0", в противном случае выбирается "cpu", но все равно настоятельно рекомендую выбрать видеокарту при выборе среды выполнения.


5. обрезка и визуализация части датасета


6. 1. Функция принимает модель model, функцию потерь criterion, оптимизатор optimizer, планировщик scheduler и количество эпох num_epochs (по умолчанию равное 25).
  2. Создается временный каталог для сохранения контрольных точек обучения с помощью TemporaryDirectory, и в нем создается путь к файлу для сохранения лучших параметров модели.
  
  3. Состояние модели сохраняется в файл с помощью torch.save.
  
  4. Затем происходит обучение на протяжении num_epochs.
  
  5. В каждой эпохе происходит обход данных обучения и валидации ('train' и 'val').
  
  6. Для каждой фазы (обучение и валидация) выполняются следующие шаги:
      - Устанавливается режим модели (model.train() для обучения и model.eval() для оценки).
      - Вычисляется потеря и производятся обратное распространение и оптимизация только во время обучения.
      - Вычисляются статистики, такие как потери и точность.
      - Планировщик шагов (scheduler.step()) вызывается только во время обучения.
  
  7. Если точность валидации лучше предыдущей лучшей точности (best_acc), состояние модели сохраняется в файл лучших параметров.
  
  8. По завершении обучения загружаются лучшие параметры модели, и функция возвращает обученную модель.
  
  Эта функция позволяет обучать модель на наборе данных, вычисляя потери и точность на обучающем и валидационном наборах данных, и сохраняя лучшие параметры модели.


7. этот блок предназначен для визуализации работы модели машинного обучения. Он принимает модель и количество изображений в качестве входных параметров. Затем он переключает модель в режим оценки (evaluation mode) с помощью model.eval() и перебирает изображения из валидационного набора данных. 

Для каждого изображения модель делает предсказание, отображает его на графике вместе с соответствующей меткой и проверяет количество отображенных изображений. Как только было отображено заданное количество изображений, модель возвращается в исходный режим (был ли она обучена или нет).


8. Этот блок  выполняет несколько действий в контексте обучения нейронной сети.
  1. Загружает предварительно обученную модель ResNet-18 с весами из ImageNet и для слоя полносвязного соединения (fully connected layer) регистрирует "перехватчик" (hook), который применяет dropout с вероятностью 0.5 после прямого прохода модели.
  
  2. Затем код изменяет слой fc (fully connected) модели, заменяя его на новый слой типа nn.Linear с количеством входных признаков, которые были установлены для предварительно обученной модели.
  
  3. После этого модель переносится на указанное устройство (device), вероятно, на GPU.
  
  4. Задается функция потерь (loss function) - кросс-энтропия (CrossEntropyLoss).
  
  5. Создается оптимизатор SGD (Stochastic Gradient Descent) для обучения модели с указанной скоростью обучения (learning rate) и коэффициентом momentum.
  
  6. Устанавливается шаговый планировщик (stepLR) для уменьшения скорости обучения на заданный коэффициент каждые 7 эпох

  
9. обучение модели по эпохам

    
10. визуализация ответов ИИ

    
11.Этот блок решает задачу тонкой настройки (fine-tuning) предварительно обученной модели ResNet-18 для новой задачи классификации.

  1. Загружается предварительно обученная модель ResNet-18 с весами из ImageNet и для слоя полносвязного соединения (fully connected layer) регистрируется "перехватчик" (hook), который применяет dropout с вероятностью 0.5 после прямого прохода модели.
  
  2. Все параметры предварительно обученной модели замораживаются (requires_grad = False), чтобы предотвратить их обновление во время обучения.
  
  3. Создается новый слой полносвязного соединения (fully connected layer) для адаптации модели к новой задаче классификации на 8 классов.
  
  4. Модель переносится на указанное устройство (device), вероятно, на GPU.
  
  5. Задается функция потерь (loss function) - кросс-энтропия (CrossEntropyLoss).
  
  6. Создается оптимизатор SGD (Stochastic Gradient Descent) только для обучения параметров финального слоя (fully connected layer) с указанной скоростью обучения (learning rate) и коэффициентом momentum.
  
  7. Устанавливается шаговый планировщик (stepLR) для уменьшения скорости обучения на заданный коэффициент каждые 7 эпох обучения.
  
  Этот код подготавливает модель к выполнению тонкой настройки на новых данных, используя предварительно обученные веса модели ResNet-18 и обучая только последний слой для новой задачи классификации. 


12. обучение модели по эпохам


13. визуализация ответов ИИ
    

14. Этот блок представляет собой функцию для визуализации предсказаний модели машинного обучения на конкретном изображении.

Функция принимает модель и путь к изображению в качестве входных параметров. Затем она переключает модель в режим оценки (evaluation mode) и обрабатывает входное изображение, применяя к нему соответствующие преобразования данных. После этого изображение подается на устройство (device).

С использованием модели, функция делает предсказание для входного изображения и отображает его вместе с соответствующей меткой на графике.

После этого модель возвращается в исходный режим обучения (была ли она обучена или нет).

Эта функция полезна для наглядного представления того, как модель делает предсказания на отдельных изображениях.


15. визуализация ответа ИИ на изображение пользователя.
